# CreditScoring
do some classification for credit scoring based on sickit-learn.

As public data sets for credit scoring are limited, I choose the UCI reposiory - German stalog data & Australian data.
希望可以借此项目将机器学习中的各种分类器的算法、优缺点、改进算法等都理清楚。机器学习（这里先不谈深度学习）问题的常规流程是数据采集-》数据预处理-》特征提取-》分类/聚类-》应用，无论是文本、视频、音频、图像，无论是要实现什么样的应用，文本搜索、语言模型、视频检索、机器翻译、图像识别，最终都会转化成一个一个的矩阵、向量的计算，要么分类要么聚类。然而不同的是数据类型不同，特征的裁定以及抽取方式就不同，数据量级也不同，所以这么多的研究方向虽然需要的研究基础都相似，但是要在各自领域达到顶尖就需要不同的方式。数据采集阶段，文本需要爬虫，图像、音视频也许还要人工获取，这个就是非常重要的dataset建设，其中监督学习需要的标定是最困难的，ImageNet就是在amazon上雇人标定，用众包的方式猜得到了这上千万张图和label，更多的情况就是自己在实验室辛苦地标，但是这一过程虽然靠的是体力，但是一劳永逸。数据预处理就是数字化、标准化采集得到的原始数据，文本也许就是字典学习，图片视频音频也许就是将信号数字化矩阵化，便于下一步的学习，有时还需要剔除噪声，降维等。特征提取是一个研究领域，意味着要对数据有一个representation，深度学习就是把后面的部分都省略，直接在这一步把事情解决==！但是传统的机器学习，不同数据类型会有各自不同的特征，文本的tfidf，图像的hog,lbp,pixel,sift等，这一步还需要考验人对数据的理解。分类/聚类就是学习的过程，有监督学习无监督学习这里不详述，总之机器学习靠的就是这些了。
因此，无论我将从事哪一个领域的研究，都离不开分类器，分类器再怎么发展，有些基础也是怎么也不会过时。这个项目就是我自己个人对分类器的一些理解，希望做一个记录，对今后的科研和学习有点帮助。
对这些算法的学习，主要来自于李航老师的《统计学习方法》，《PR & ML》， 《Pattern classification》.

(1)KNN

k近邻法是一种基本分类与回归方法。k值的选择、距离度量和分类决策规则是k近邻法则的三个基本要素。

(2)Decision Tree
(3)SVM
(4)LR
(5)NB
(6)ANN
(7)boosting
(8)bagging
(9)stacking
